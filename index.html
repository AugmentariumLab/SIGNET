<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>SIGNET: Efficient Neural Representations For Light Fields
    | Brandon Y. Feng Amitabh Varshney International Conference on Computer Vision (ICCV 2021) - Oral</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="SIGNET: Efficient Neural Representations For Light Fields
" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Brandon Y. Feng Amitabh Varshney International Conference on Computer Vision (ICCV 2021) - Oral" />
<meta property="og:description" content="Brandon Y. Feng Amitabh Varshney IEEE Transactions on Visualization and Computer Graphics (IEEE VR 2021) TVCG - Honorable Mention" />
<link rel="canonical" href="https://augmentariumlab.github.io/SIGNET/" />
<meta property="og:url" content="https://augmentariumlab.github.io/SIGNET/" />
<meta property="og:site_name" content="SIGNET: Efficient Neural Representations For Light Fields
" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="SIGNET: Efficient Neural Representations For Light Fields
" />
<script type="application/ld+json">
{"headline":"SIGNET: Efficient Neural Representations For Light Fields","description":"Brandon Y. Feng Amitabh Varshney International Conference on Computer Vision (ICCV 2021) Mention","url":"https://augmentariumlab.github.io/SIGNET/","@type":"WebSite","name":"SIGNET: Efficient Neural Representations For Light Fields
","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="/foveated-360-video/assets/css/style.css">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">SIGNET: Efficient Neural Representations For Light Fields
</h1>
      <h2 class="project-tagline"><div style="display: flex; flex-direction: row; color: #FFF; flex-wrap: wrap;"> <a href="https://brandonyfeng.github.io" style="margin-left:1rem; flex-grow: 1; color: #FFF;">Brandon Y. Feng <a href="http://www.cs.umd.edu/~varshney/" style="margin-left:1rem; flex-grow: 1; color: #FFF;">Amitabh Varshney</a> </div> <p style="margin-bottom: -3rem;"> International Conference on Computer Vision (ICCV 2021)<br> - Oral </p></h2>
      
    </section>

    <section class="main-content">
      
<iframe width="560" height="315" src="https://www.youtube.com/embed/AjSuUTvQnFg" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" style="max-width: 100%; position: relative; left: 50%; transform: translateX(-50%);"></iframe>

<h2 id="abstract">Abstract</h2>

<!--<p><a href="https://duruofei.com/papers/Li_ALog-RectilinearTransformationForFoveated360-DegreeVideoStreaming_TVCG2021.pdf"><img src="/foveated-360-video/resources/teaser.png" alt="Teaser image of A Log-Rectilinear Transformation for Foveated 360-degree Video Streaming" /></a></p>-->

<p>With the rapidly increasing resolutions of 360째 cameras, head-mounted displays, and live-streaming services, streaming high-resolution panoramic videos over limited-bandwidth networks is becoming a critical challenge. Foveated video streaming can address this rising challenge in the context of eye-tracking-equipped virtual reality head-mounted displays. However, conventional log-polar foveated rendering suffers from a number of visual artifacts such as aliasing and flickering. In this paper, we introduce a new log-rectilinear transformation that incorporates summed-area table filtering and off-the-shelf video codecs to enable foveated streaming of 360째 videos suitable for VR headsets with built-in eye-tracking. To validate our approach, we build a client-server system prototype for streaming 360째 videos which leverages parallel algorithms over real-time video transcoding. We conduct quantitative experiments on an existing 360째 video dataset and observe that the log-rectilinear transformation paired with summed-area table filtering heavily reduces flickering compared to log-polar subsampling while also yielding an additional 11% reduction in bandwidth usage.</p>

<h2 id="downloads">Downloads</h2>

<div style="display: flex; text-align:center; flex-direction: row; flex-wrap: wrap;">
<div style="margin:1rem; flex-grow: 1;"><a href="https://brandonyfeng.github.io/papers/SIGNET.pdf"><img style="max-width:10rem;" src="resources/paper.jpg" /><br /><label>Paper</label></a><br /></div>
<div style="margin:1rem; flex-grow: 1;"><a href="resources/Supplementary.pdf"><img style="max-width:10rem;" src="resources/supplementary.jpg" /><br />Supplementary</a></div>
<div style="margin:1rem; flex-grow: 1;"><a href="https://github.com/AugmentariumLab/SIGNET"><img style="max-width:10rem;" src="resources/github.jpg" /><br />Code</a></div>
<div style="margin:1rem; flex-grow: 1;"><a href="https://docs.google.com/presentation/d/15iIS2_9XapnSUtHnTNXNibJ7aeYD9ZYEnJqey0AlB88"><img style="max-width:10rem;" src="resources/slides.jpg" /><br />Slides</a></div>
</div>

<h2 id="citation">Citation</h2>

<div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Feng2021SIGNET</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Feng, Brandon Y. and Varshney, Amitabh}</span><span class="p">,</span>
  <span class="na">booktitle</span><span class="p">=</span><span class="s">{International Conference on Computer Vision (ICCV 2021)}</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{SIGNET: Efficient Neural Representations For Light Fields}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Brandon Y. Feng and Amitabh Varshney. 2021. SIGNET: Efficient Neural Representations For Light Fields. International Conference on Computer Vision (ICCV 2021)</p>

      <footer class="site-footer">
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </section>

    
  </body>
</html>
